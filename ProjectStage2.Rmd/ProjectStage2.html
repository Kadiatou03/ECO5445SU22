---
title: "Project Stage 02 Kadiatou Sogodogo"
output: html_document
date: '2022-07-25'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}

library(readr)
library(Matrix)
library(dplyr)
library(car)
library(gamlr)
library(boot)
library(pROC)
library(rpart)
library(rpart.plot)
library(party)
library(randomForest)
library(e1071)
```
                                    
#                                    Part A: Data Collection and rearrangement
# Importing the dataset into R

```{r}
library(readr)
mortgage <- read_csv("~/GitHub/ECO5445/Project/Data/hmda_sw.csv", col_types="ccddd")


```


## Cleaning data from missing numeric data hard coded as 999,999.4 and 999,999

```{r}
mortgage [mortgage == 999999.4] <- NA
mortgage [mortgage == 999999] <- NA

```

## Renanming some variables of interest

```{r}
library(dplyr)
mortgage <- rename(mortgage, "Deny_Approve" = "s7", "Loan_amount" = "s6" , "Race" = "s13" , "No_dependents" =  "s24a", "Years_employed" = "s25a" , "Liquid_assets"= "s35", "ExpensesIncome" = "s45", "ObligationsIncome" = "s46", "Self_employed" = "s27a", "Marital_status" = "s23a", "Education" = "school", "Income" = "s17", "Net_worth" =  "netw", "Unemployed_Prob" = "uria", "MTG_credit_hist" = "s42", "Consum_credit_hist" = "s43", "Appraised_value"="s50")
```

# Initial Choice of variables

Slightly changed from project stage 01, this will provide intuitive information on representative applicant while doing summary statistics.

The variables chosen are the applicants race (A_race) to test the main hypothesis, their annual income (Income), the two Debt-to-income ratios ( Expenses/income ) and ( obligations/income ) that shows applicant's debts obligations compared to their income and applicants' ability to pay back a loan, their marital status(Marital_status) which could affect the stability of the household income, as well as their level of education (Education) which can approximate their earnings and allows speculations about their credit worthiness. 
 
The sample also shows whether applicants are self-employed (Self_employed) because self-employed individuals tend to suffer more income risk and their earnings are more difficult to verify. The sample accounts for the Applicants' probability of unemployment (Unemployed_Prob) which is also important because lenders are skeptical about individuals who are employed in depressed sectors of regional economy, as well as the number of years employed in applicable line of work (Years_employed) as a strong employment history proves the applicant has a steady income and ability to make regular loan payments.

The sample further includes variables such as the number of dependents('No_dependents') which can affect the income available to carry the loan, the type of action taken by lenders(Deny_Approve), the Loan amount requested by applicants (Loan_amount), the applicants' credit history:(MTG_credit_history) and (Consum_credit_hist) because the more severe applicant's past credit problems are, the higher the probability that their loans are denied. Furthermore, the sample has applicants' liquid assets in dollar amounts which can be easily trade for cash within a short amount of time to pay mortgage if necessary. Finally, the selection contains information about the applicants' net worth which determine what us left after subtracting liabilities from assets, in other terms, what they own after subtracting what they owe. This can be used to calculate the applicant's probability of default.

# Dataframe with the variables selected: SampleStatistics 

```{r}
SampleStatistics <- select(mortgage, Deny_Approve, Loan_amount, Race, No_dependents, Years_employed, ExpensesIncome, ObligationsIncome, Self_employed, Marital_status, Education, Unemployed_Prob, Income, Liquid_assets, Net_worth, MTG_credit_hist, Consum_credit_hist, Appraised_value)

```

## Assigning labels to categorical variables

```{r}
SampleStatistics$Deny_Approve <- factor(SampleStatistics$Deny_Approve,levels = c(1,2,3), labels = c("Approve", "Approve","Deny"))
SampleStatistics$Race <- factor(SampleStatistics$Race,levels = c(3,5), labels = c("Black", "White"))
SampleStatistics$Marital_status <- factor(SampleStatistics$Marital_status ,levels = c('M','U','S'), labels = c("Married", "Unmarried", "separated"))
SampleStatistics$Self_employed <- factor(SampleStatistics$Self_employed, levels = c(0,1), labels = c("No", "Yes"))
SampleStatistics$MTG_credit_hist <- factor(SampleStatistics$MTG_credit_hist, levels = c(1,2,3,3), labels = c("Excellent","No record","Fair", "bad"))
SampleStatistics$Consum_credit_hist <- factor(SampleStatistics$Consum_credit_hist, levels = c(1,2,3,4,5,6), labels = c("Excellent", "good", "fair", "Insufficient record", "bad", "Serious"))
```

## Hypotheses

Given the sample, the following hypotheses are build on the quantitative variables based on information provided in the paper. The relationship direction is indicated by (+) and (-).  

H1: The higher the appraisal value, the higher the loan amount (loan is based on the appraisal) (+)
H2: The higher the income, the higher loan amount, (individuals would not borrowed beyond what they can afford to pay back) (+)
H3: The higher the loan amount, the lower the two Debt-to-income ratios, (showing ability to pay) (-) 
H4: The higher the number of dependents, the higher Expenses/income (showing effect of dependent on debt to income ratio) (+)
H5: The higher the number of years of education, the higher employment years (More educated individuals tend to be stable on the job market) (+)
H6: The higher the income, the lower the two Debt-to-income ratios (Displaying ability to pay back loan) (-)
H7: The higher the number of years of education, the lower the probability of being unemployed (More educated individuals have low unemployment probability) (-)
H8: The higher the number of years of education, the higher the income (+)
H9: The higher the net worth, the higher the loan amount (a high net worth could indicate ability to borrow high loan) (+) 


#Narrowing down the initial Quantitatives variables selection

This will provide  more insightful scatterplots and histograms.

The new selection contains the most relevant variables to the mortgage application approval/denial process and it is based on the results of the studies provided in the paper. This new selection will facilitate suggestions for transforming variables in the logistic regression as well as a better visualizations of scatterplots and histograms. The result of the different analysis performed on the HMDA Data, suggests that the net wealth coefficient and the number of dependents had no significant effect on the mortgage lending decision (pg.35 and pg.38). On the other hand, the level of education and years on the job were generally statistically significant.Liquid assets also do not appear to affect the probability of denial. Moreover employment risk has no significant effect on the estimated effect of race in the mortgage lending decision( pg.39).Additionally, houses' appraised value and the loan amount do not seem to play significant roles in the lending process. Altogether, the quantitative variables left are Loan_amount, ExpensesIncome, ObligationsIncome, Education, Income, Years_employed and they will constitute the the new set of quantitative variables. 

## The new sample selection of Quantitavive variables

```{r}
QuantitativeSample <- select(mortgage, Loan_amount, No_dependents, Years_employed, ExpensesIncome, ObligationsIncome, Education, Unemployed_Prob, Income, Liquid_assets, Net_worth, Appraised_value)

NewQuantitativeSample <- select(QuantitativeSample, ExpensesIncome, ObligationsIncome, Education, Income, Years_employed)
```
                                     
#                                   Part B: Summary statistics and data vizualization
                                      
                                    
## Correlation between all the quantitative variables from the initial sample

```{r}
QuantitativeSample <- select(mortgage, Loan_amount, No_dependents, Years_employed, ExpensesIncome, ObligationsIncome, Education, Unemployed_Prob, Income, Liquid_assets, Net_worth, Appraised_value)

cor(na.omit(QuantitativeSample))

```

## Testing the hypotheses through Correlation: Results

Some interesting Correlations were used to test the hypotheses.

H1 Result: Corr = 0.72674. As predicted, there is a positive relationship between the variables and it is quite strong. High loan amounts should be backed by an appropriate appraisal value.

H2 Result: Corr = 0.57994. As predicted, there is a positive relationship between the variables that is fairly strong. The annual income should be enough to cover the loan amount.

H3a Result: Corr = 0.06986. The result does not agree with the H3. There is a very weak relationship between the variables which indicates that they may not be correlated. Therefore, the debt ratio does not influence the loan amount.

H3a Result: Corr = 0.062999. This result also does not agree with H3. There is a very weak relationship between the variables which indicates that they may not be correlated. Therefore, the debt ratio does not influence the loan amount.

H4 Result: Corr = 0.024701, this extremely weak correlation does not agree with H4 and may indicate that the number of dependent do not have a significant effect on the debt ratio (Expenses/income)

H5 Result: Corr = 0.202061. H5 is weakly proven by this correlation but there is a slightly moderate and positive relationship between the number of years being employed and the level of education.

H6a Result: Corr = -0.23911554.As predicted, there is a negative relationship and the variables are inversely correlated. Nonetheless, it is still a weak correlation meaning that as income increases, expenses/income ratio slightly decreases.

H6b Result: Corr = -0.161756828. H6 is weakly proven as the low negative coefficient indicates that the two variables are negatively correlated but on a very moderated level. Therefore, as income increases, Obligations/income ratio slightly decreases

H7 Result: Corr = 0.011410. The coefficient is positive but so low, that there may be not a relationship between the level of education and the numbers of years being employed. Therefore, H7 is not proven.

H8 Result: Corr = 0.24898115. H8 predicted a positive relationship which is correct, but the low coefficient suggests there is a a weak correlation between the level of education and income.

H9 Result: Corr= 0.2022157. As predicted, there is a positive relationship between net worth and loan amount. Nonetheless, it is still a weak correlation which indicates when the increase in net worth only slightly increase the loan amount that applicants can afford to pay back.

## Basis summary statistics and standard deviation of quantitative variables from the new sample selection of Quantitavive variables

```{r}
summary(SampleStatistics)

ExpensesIncome.Standard.Deviation <- sd(SampleStatistics$ExpensesIncome)
ExpensesIncome.Standard.Deviation

ObligationsIncome.Standard.Deviation <- sd(SampleStatistics$ObligationsIncome) 
ObligationsIncome.Standard.Deviation

Education.Standard.Deviation <- sd(na.omit(SampleStatistics$Education))
Education.Standard.Deviation 

Income.Standard.Deviation <- sd(na.omit(SampleStatistics$Income))
Income.Standard.Deviation

Years_employed.Standard.Deviation <- sd(na.omit(SampleStatistics$Years_employed))
Years_employed.Standard.Deviation

```


The summary statistics shows that there are 2095 applications approved and 285 applications denied with 339 black applicants and 2041 applicants. The summary indicates that on average, applicants request around 139,300 dollars from banks and other lending institutions to finance their house purchase and the average appraisal value of houses is 197,800 dollars. The average debt to income is 25.53 for expenses over income and 33.08 for obligations over income meaning that average applicant has 25.53 of monthly gross income that goes toward paying expenses and 33.08 towards paying obligations. The standard deviation of the ratios are similar and they are respectively 9.66 and 10.73. These standard deviations show that the data are slighlty clustered around the mean for the debt ratios. 277 applicants are Self_employed out of 2380 and 1444 of them are married, 860 unmarried and 74 separated. The average applicant has zero or one dependent and their annual income is approximately 76,120 dollars.The standard deviation here(66.15) is the highest given the data type. This tells that the data for annual income are spread out. The average of the different probabilities of unemployment by industry is 3% and on average, applicants level of education is around 15.5 years of school and the average numbers of years being employed in applicable line of work is 10.59. The standard deviation of education is 2.87 meaning that the data are clustered around the mean and for years of employment, it is 7.73 which indicate a moderate spread. The average net worth of applicants and co-applicants is 253.04 dollars. On the other hand, applicant's liquids assets on average is worth 93,070 dollars. Finally, most applicants have either an excellent credit history of mortgage payments or no mortgage payment history; additionally, nearly half of applicants have a great credit history of consumer payments. 


# Histograms for quantitative variables from new sample

```{r}
attach(NewQuantitativeSample)
par(mfrow = c(2, 3))

hist(ExpensesIncome)
hist(ObligationsIncome)
hist(Education)
hist(Income)
hist(Years_employed)
```
Except for the level of education, all of the quantitative variables in the new sample seem to present sightly right skewed distributions. This tells that the mean is typically less than the median which is closer to the third quarterly than to the first quartile. For each one, we can see what are the most common values and the range within which most applicants fall into. There is no outlier observable.  

# Scatterplots

```{r}
library(car)
scatterplotMatrix(NewQuantitativeSample, main = "Quantitative Variables Scatterplots")
```

The scatterplots show the trend between the data and depict the relationship between variables. This can help test some of the hypotheses presented earlier. For most of them, points are clustered and form a curve or line. We can imply that there is moderate to strong relationship between the variables and we have linear and non linear relationships.

# Barcharts for qualitative variables

```{r}
Deny_Approve <- table(SampleStatistics$Deny_Approve)
barplot(Deny_Approve, main =" Decision", col=c("darkblue","red"),legend = rownames(Deny_Approve))

Race <- table(SampleStatistics$Race)
barplot(Race, main ="Race", col=c("darkblue","yellow"),legend = rownames(Race))

Marital_status <- table(SampleStatistics$Marital_status) 
barplot(Marital_status, main ="Marital Status", col=c("darkblue","red","Yellow"),legend = rownames(Marital_status))

Self_employed <- table(SampleStatistics$Self_employed)
barplot(Self_employed, main ="Self-employed ?", col=c("darkblue","Yellow"),legend = rownames(Self_employed))
  
MTG_credit_hist <- table(SampleStatistics$MTG_credit_hist) 
barplot(MTG_credit_hist, main = "Credit history - mortgage payments", col = c("darkblue","red","Yellow","orange"), legend =rownames(MTG_credit_hist))  

Consum_credit_hist <- table(SampleStatistics$Consum_credit_hist) 
barplot(Consum_credit_hist, main = "Credit history - consumer payments", col = c("darkgreen","darkblue","purple","Yellow","orange","red"), legend =rownames(Consum_credit_hist))  

```
The barcharts constitute a great way to visualize the qualitative variables from the sample. Each one shows the different categories within the variables and  their spread. This helps knowing exactly how many applicants fall into each category.

# Transformation needed
Overall, the plots, histograms, and barcharts provide a great visualization of the data which will help determine the necessary transformation for modeling. This could include log and polynomial transformations of the two debt ratios and the creation of interaction variables such as Race and obligation over income, expenses over income  and obligation over income. 

#                                  Part C: logistic regression model, the ROC curve and the AUC 

# Logistic regression model    
```{r}
Reg.Sample <- select(SampleStatistics, Deny_Approve, Race, ExpensesIncome, ObligationsIncome, Self_employed, Marital_status, Education)

set.seed(1234)
Train <- sample(nrow(Reg.Sample), 0.7*nrow(Reg.Sample))

dataTrain <- Reg.Sample[Train,]
dataValidate <- Reg.Sample[-Train,]
 
SampleRegression <- select(dataTrain, Deny_Approve, Race, ExpensesIncome, ObligationsIncome, Self_employed, Marital_status, Education)
SampleRegression$Deny_Approve <- ifelse(SampleRegression$Deny_Approve == 'Approve',1,0)

library(gvlma)
FitSampleRegression <- glm(Deny_Approve ~ ObligationsIncome + ExpensesIncome + Race + Self_employed + Marital_status + Education, data = SampleRegression, family = "binomial")

summary(FitSampleRegression)
```
From this model, we observe that at the 95% level, Obligations over income, race, self-employment, marital status and the level of education are tested significant. The positive coefficient indicates a positive relationship with dependent variable and the negative coefficient, a negative relationship. This regression tells that for every increase by one in Obligations over income ratio, number of self-employed, the number of unmarried and separated applicants, the chance of being approved decreases respectively by 0.07811, 0.59692, 0.51745 and 0.22102. On the other hand, for every increase by one in expenses over income ratio, the number of white applicants and the level of education the chance of being approved increase by respectively  0.01053, 1.33843, 0.08973.

Theses results help better understand as well as confirm and refute some of the hypotheses. For instance, H6 states that the higher the income, the lower the two Debt-to-income ratios which display ability to pay back loan. Therefore, this will increase the chance of being approved. The coefficients indicated that any increase in Obligations over income ratio, lowers approval probability, however an increase in expenses over income ratio will increase approval probability. This hypotheses was therefore refuted. The results also tell that hypothesis on some of the variables are not significant therefore they will display very weak correlations. 


# ROC Curve
```{r}
prob <- predict(FitSampleRegression, dataValidate, type = 'response')

my_roc <- roc(dataValidate$Deny_Approve ~ prob, plot = TRUE, print.auc=TRUE)
```
Since the ROC curve is a performance measurement for the classification problems, a 0.594 as the area under the curve means that there is 59% chance that the model would be able to segregate the data and rank order them correctly. This is close to randomly flipping a coin type of classification. In general the higher the AUC, the better the quality of classification.

## Threshold
```{r}
threshold <- coords(my_roc, "best", ret = "threshold")

as.numeric(threshold)
```
The threshold that maximizes the sensitivity and specificity is 0.8881954

# The confusion matrix at alternative cut-off levels

## Confusion matrix 1

```{r}
prob <- predict(FitSampleRegression, dataValidate, type = 'response')

logit.pred <- factor(prob > 0.5, levels = c(FALSE,TRUE),
                     labels = c("Approve","Deny"))

logit.perf <- table(dataValidate$Deny_Approve, logit.pred, dnn = c("Actual","Predicted"))

logit.perf
```
Here, we can see that a large majority of the predictions were wrong. The classification is clearly poorly made. 

## Confusion matrix 2

```{r}
prob <- predict(FitSampleRegression, dataValidate, type = 'response')

logit.pred.thres <- factor(prob > as.numeric(threshold), levels = c(FALSE,TRUE),
                     labels = c("Approve","Deny"))

logit.perf.thres <- table(dataValidate$Deny_Approve, logit.pred.thres, dnn = c("Actual","Predicted"))

logit.perf.thres

```
Here,there is slight improvement in the accuracy of the classifications

# Performance Measures Calculation

This section include the classifier sensitivity, specificity, the false-positive rate, the false-negative rate, the model accuracy and error rate to confirm they are the same as those produced by R

## Creating the performance function
```{r}
performance <- function(table, n = 4){
  if(!all(dim(table) == c(2,2)))
    stop("Must be a 2 x 2 table")
  tn = table[1,1]
  fp = table[1,2]
  fn = table[2,1]
  tp = table[2,2]
  sensitivity = tp/(tp+fn)
  specificity = tn/(tn+fp)
  ppp = tp/(tp+fp)
  npp = tn/(tn+fp)
  hitrate = (tp+tn)/(tp+tn+fp+fn)
  result <- paste0("Sensitivity = ", round(sensitivity,n),
                   "\nSpecificity = ",round(specificity,n),
                   "\nPositive Predictive Value = ", round(ppp,n),
                   "\nNegative Predictive Value = ", round(npp,n),
                   "\nAccuracy = ", round(hitrate,n))
  cat(result)
}
```

## Performance Calculation
```{r}
performance(logit.perf)

performance(logit.perf.thres)
```

The performance analysis shows that at a cut-off level of 0.5, the prediction accuracy is 12.19%. According the model, there is a 94.05% probability that proportion of applicants are correctly identified as approved and there is 1.28% probability that are correctly identified by as denied.

On the other hand, at the threshold cut-off level, the prediction accuracy is at 30.51%. There is 47.62% probability that proportion of applicants are correctly identified as approved and there is 28.21% probability that applicants are correctly identified by as denied.

#                                                  Part D: Cross validation
                                                  
The Cross validation will be executed with the same variables used in the logistic Regression.
```{r}
sampleCv <-select(SampleStatistics, Deny_Approve, Race, ExpensesIncome, ObligationsIncome, Self_employed, Marital_status, Education)
```
Before performing 10-fold cross validation, a new data set will be created containing new columns where numerical labels will be assigned to categorical data creating dummy variables. We will also create a train and validate data from the sample.

# Preparing the data for Cross validation 
```{r}
#New columns
sampleCv$Unmarried = sampleCv$Marital_status
sampleCv$Separated = sampleCv$Marital_status

#Dropping marital status column
sampleCv <- subset(sampleCv, select= -Marital_status)

#reassigning numerical labels
sampleCv$Deny_Approve <- ifelse(sampleCv$Deny_Approve == 'Approve',1,0)
sampleCv$Race <- ifelse(sampleCv$Race == 'White',1, 0) 
sampleCv$Unmarried <- ifelse(sampleCv$Unmarried  == 'Unmarried',1, 0) 
sampleCv$Separated <- ifelse(sampleCv$Separated  == 'Separated',1, 0)
sampleCv$Self_employed <- ifelse(sampleCv$Self_employed  == 'yes',1, 0)

# Separating the data
set.seed(1234)
Train.cv <- sample(nrow(sampleCv), 0.7*nrow(sampleCv))

dataTrain.cv <- sampleCv[Train.cv,]
dataValidate.cv <- sampleCv[-Train.cv,]
sampleCv <- na.roughfix(sampleCv)
``` 


# Differents Logistic regression models using 10-fold cross validation

## Model 1 with polynomial transformation
```{r}
cv1<- glm(Deny_Approve ~ ObligationsIncome +  poly(ExpensesIncome,3) + Self_employed + Unmarried + Separated + Education, data = sampleCv, family = "binomial")
set.seed(123)
mse.cv <- cv.glm(sampleCv, cv1, K = 10)$delta[]
mse.cv

summary(cv1)$coef
```

## Model 2 with interaction variables
```{r}
cv2<- glm(Deny_Approve ~ I(ObligationsIncome*ExpensesIncome)+ ObligationsIncome + Race + ExpensesIncome + Unmarried + Separated + Education, data = sampleCv, family = "binomial")
set.seed(123)
mse.cv <- cv.glm(sampleCv, cv2, K = 10)$delta[]
mse.cv

summary(cv2)$coef
```

## Model 3 with polynomial transformation and interaction variables
```{r}
cv3 <- glm(Deny_Approve ~ poly(ObligationsIncome,2) + I(ObligationsIncome*ExpensesIncome) + Race + Self_employed + Unmarried + Separated + Education, data = sampleCv, family = "binomial")
set.seed(123)
mse.cv <- cv.glm(sampleCv, cv3, K = 10)$delta[]
mse.cv

summary(cv3)$coef
```

## Model 4 with polynomial transformations
```{r}
cv4 <- glm(Deny_Approve ~ poly(ObligationsIncome,3) + poly(ExpensesIncome,3) + Race + Self_employed + Unmarried + Separated + Education, data = sampleCv, family = "binomial")
set.seed(123)
mse.cv <- cv.glm(sampleCv, cv4, K = 10)$delta[]
mse.cv

summary(cv4)$coef
```
## Model 5 with log transformations
```{r}
sampleCv$logObligationsIncome =log(sampleCv$ObligationsIncome)
sampleCv$logExpensesIncome =log(sampleCv$ExpensesIncome)

sampleCv [sampleCv == -Inf] <- NA

cv5<- glm(Deny_Approve ~ logObligationsIncome + logExpensesIncome + Race + Self_employed + Unmarried + Separated + Education, data = sampleCv, family = "binomial")

mse.cv <- cv.glm(sampleCv, cv3, K = 10)$delta[]
mse.cv
summary(cv3)$coef
```
# Performance measure calculations with the average mse

```{r}
mse.cv<- NULL

for (i in 1:5) {
  model<- glm(Deny_Approve ~ poly(ObligationsIncome,i, raw=TRUE) + poly(ExpensesIncome,i, raw=TRUE) + I(ObligationsIncome*Race) + Race + Self_employed + Unmarried + Separated + Education, data = sampleCv, family = "binomial")
set.seed(123)
mse.cv[i] <- cv.glm(sampleCv, model, K = 10)$delta[1]
 
}
mse.cv
```
```{r}
mse.cv<- matrix(1:25, 5, 5)

for (i in 1:5) {
  for(j in 1:5){
  model<- glm(Deny_Approve ~ poly(ObligationsIncome,i, raw=TRUE) + poly(ExpensesIncome,j, raw=TRUE) + Race + Self_employed + Unmarried + Separated + Education, data = sampleCv, family = "binomial")
set.seed(123)
mse.cv[i] <- cv.glm(sampleCv, model, K = 10)$delta[1]
} 
}
mse.cv
```
```{r}
min = which(mse.cv == min(mse.cv), arr.ind=TRUE)
min
```
The min average mse occurs when i= 1,2,3 and when j= 1. Therefore, the superior model include polynomial transformation on the variables obligations over income.


## Threshold and other Performance measures at threshold level
### Model 1
```{r}
prob.cv <- predict(cv1, dataValidate.cv, type = 'response')
my_roc.cv1 <- roc(dataValidate.cv$Deny_Approve ~ prob.cv)
threshold.cv1 <-coords(my_roc.cv1, "best", ret = "threshold")

threshold.cv1 = as.numeric(threshold.cv1)
threshold.cv1
```

```{r}
prob.cv <- predict(cv1, dataValidate.cv, type = 'response')

logit.pred.cv1 <- factor(prob.cv > threshold.cv1, levels = c(FALSE,TRUE),labels = c("Approve","Deny"))
logit.perf.cv1 <- table(dataValidate.cv$Deny_Approve, logit.pred.cv1, dnn = c("Actual","Predicted"))

logit.perf.cv1
```
In this model, the threshold that maximizes the sensitivity and specificity is  0.8348627 and the prediction is not efficient.

### Model 2

```{r}
prob.cv <- predict(cv2, dataValidate.cv, type = 'response')
my_roc.cv2 <- roc(dataValidate.cv$Deny_Approve ~ prob.cv)
threshold.cv2 <-coords(my_roc.cv2, "best", ret = "threshold")

threshold.cv2 = as.numeric(threshold.cv2)
threshold.cv2
```

```{r}

logit.pred.cv2 <- factor(prob.cv > threshold.cv2, levels = c(FALSE,TRUE),labels = c("Approve","Deny"))
logit.perf.cv2 <- table(dataValidate.cv$Deny_Approve, logit.pred.cv1, dnn = c("Actual","Predicted"))

logit.perf.cv2
```
In this model, the threshold that maximizes the sensitivity and specificity is 0.8683657 and the prediction has not changed.

## Model 3
```{r}
prob.cv <- predict(cv3, dataValidate.cv, type = 'response')
my_roc.cv3 <- roc(dataValidate.cv$Deny_Approve ~ prob.cv)
threshold.cv3 <-coords(my_roc.cv3, "best", ret = "threshold")

threshold.cv3 = as.numeric(threshold.cv3)
threshold.cv3
```

```{r}
prob.cv <- predict(cv3, dataValidate.cv, type = 'response')
logit.pred.cv3 <- factor(prob.cv > threshold.cv3, levels = c(FALSE,TRUE),
                     labels = c("Approve","Deny"))

logit.perf.cv3 <- table(dataValidate.cv$Deny_Approve, logit.pred.cv3, dnn = c("Actual","Predicted"))

logit.perf.cv3
```
In this model, the threshold that maximizes the sensitivity and specificity is 0.8651518 and the prediction is worst than the previous ones.

# Model 4
```{r}
prob.cv <- predict(cv4, dataValidate.cv, type = 'response')
my_roc.cv4 <- roc(dataValidate.cv$Deny_Approve ~ prob.cv)
threshold.cv4 <-coords(my_roc.cv4, "best", ret = "threshold")

threshold.cv4 = as.numeric(threshold.cv4)
threshold.cv4
```


```{r}
prob.cv <- predict(cv4, dataValidate.cv, type = 'response')
logit.pred.cv4 <- factor(prob.cv > threshold.cv4, levels = c(FALSE,TRUE), labels = c("Approve","Deny"))

logit.perf.cv4 <- table(dataValidate.cv$Deny_Approve, logit.pred.cv4, dnn = c("Actual","Predicted"))

logit.perf.cv4
```
In this model, the threshold that maximizes the sensitivity and specificity is 0.8513221 and the prediction is still not efficient.

# Classification methods

## Decision Trees

### Classical Decision Trees
```{r}
set.seed(1234)

dtree <- rpart(Deny_Approve  ~ ., data = dataTrain, method = 'class' ) 
prp(dtree, type = 2, extra = 104, fallen.leaves = T)

```
#### Prediction and Performance: Pruned tree

```{r}
dtree.pred <- predict(dtree, dataValidate,type = "class")

dtree.perf <- table(dataValidate$Deny_Approve, dtree.pred, dnn = c("Actual","Predicted"))

dtree.perf
```

### Pruned tree

```{r}
dtree.pruned <- prune(dtree,cp = 0.018)

prp(dtree.pruned, type = 2, extra = 104,fallen.leaves = T)
```

##### Prediction and Performance: Pruned tree

```{r}
dtree.pruned.pred <- predict(dtree.pruned, dataValidate,type = "class")

dtree.pruned.perf <- table(dataValidate$Deny_Approve, dtree.pruned.pred, dnn = c("Actual","Predicted"))

dtree.pruned.perf
```

### Conditional Trees

```{r}
fit.ctree <- ctree(Deny_Approve ~., data = dataTrain)

plot(fit.ctree)
``` 

##### Prediction: Conditional trees

```{r}
ctree.pred <- predict(fit.ctree, dataTrain, type = 'response')
ctree.perf <- table(dataTrain$Deny_Approve, ctree.pred, dnn = c("Actual","Predicted"))
ctree.perf
```

### Random Forests

```{r}
set.seed(1234)

fit.forest <- randomForest(Deny_Approve ~., data = dataTrain, na.action=na.roughfix, importance = TRUE)

fit.forest
```

### Prediction: Random Forests

```{r}
forest.pred <- predict(fit.forest, dataValidate)

forest.perf <- table(dataValidate$Deny_Approve, forest.pred, dnn = c("Actual","Predicted"))

forest.perf
```

A summary of the variable importance
```{r}
importance(fit.forest,type = 2)
```


### Support Vector Machines
```{r}
set.seed(1234)

fit.svm <- svm(Deny_Approve ~., data = dataTrain)

fit.svm
```       

### Prediction: Support Vector Machines
```{r}
svm.pred <- predict(fit.svm, na.omit(dataValidate))
svm.perf <- table(na.omit(dataValidate)$Deny_Approve, svm.pred, dnn = c("Actual","Predicted"))
svm.perf
```



#                                            Part E: Superior Logistic Regression Model

# Identification superior logistic regression model  
The superior logistic regression model found by creating a loop function that will estimate multiple models and store the average cross validation test mse in a vector. Then, we have identify from a matrix the combination with the minimum average.

For classification purposes, the Superior Logistic Regression Model is the following:
```{r}
Superiormodel<- glm(Deny_Approve ~ poly(ObligationsIncome,3) + poly(ExpensesIncome,1) + Race + Self_employed + Unmarried + Separated + Education, data = sampleCv, family = "binomial")


summary(Superiormodel)
```
For this model, there is perfect multicollinearity where two independent variables (self-employed and Separated marital status) have an exact linear relationship between them. On the other hand, only obligations over Income to the first power is tested significant at 95% as well as race, unmarried marital status and education.

The result of the performance of the different regression models in part D
```{r}
performance(logit.perf.cv1)
performance(logit.perf.cv2)
performance(logit.perf.cv3)
performance(logit.perf.cv4)
```
Results of the performance of the classification methods

```{r}
performance(dtree.perf)
performance(ctree.perf)
performance(forest.perf)
performance(svm.perf)
performance(dtree.pruned.perf)
```

We can see that Random Forests provide the best predictions with accuracy at 88.28%

# Graph the ROC, calculate the AUC, threhold

```{r}
prob <- predict(Superiormodel, dataValidate.cv, type = 'response')
my_roc.model <- roc(dataValidate.cv$Deny_Approve ~ prob,  plot = TRUE, print.auc=TRUE)
threshold.model<-coords(my_roc.cv2, "best", ret = "threshold")

threshold.model = as.numeric(threshold.model)
threshold.model

```

# The confusion matrix at the threshold level associated with the minimum average test misclassification rate

## Confusion matrix
```{r}
logit.pred.model <- factor(prob.cv > threshold.model, levels = c(FALSE,TRUE),
                     labels = c("Deny","Approve"))

logit.perf.model <- table(dataValidate.cv$Deny_Approve, logit.pred.model, dnn = c("Actual","Predicted"))

logit.perf.model
```
With 0 meaning deny and 1, approved, the superior model is generating nice predictions the odds of applicants being approved.

# Performance measures

```{r}
performance(logit.perf.model)
```
This model is accurate at 76%

# Comparing superior logistic regression model with Part C logistic regression model

Compared to the logistic regression model Part C, this model present multicollinearity and slightly less variables tested significant. Also the ROC curve has a curve more toward the top and a slight reduced area under of curve of 0.593. Nonetheless, this new model provide better prediction with 76% accuracy compared to the logistic regression model Part C with only 30.51%.                                                 
                                                         
#                                                 Part F: Conclusion

The goal of this project is to build a mortgage application approval/denial classifier where the probability that an applicant will be approved or denied is a function observable. Through the different regressions and classifications methods, we observed that there are many variables that are tested significant at 95% level and that some of them have a higher weight in the mortgage approval process. According to the different decision trees, obligations over income is the variable that is the first criterion considered and that heavily affect the decision. if the ratio is less 50, applicants have more chance of being approved. However, if the ratio is over 50, the next criterion to achieve is an expenses over income ratio less than 26 according the classical decision tree and after the criterion that comes next is race. On the other hand, according to the conditional tree, race is the second top criterion in the mortgage approval process. The last variables by importance ranking are self-employment and marital status. Despite the divergence in rank, they all provide predictions with accuracy at approximately 88%. Our superior regression model also tells us with 76% how the changes in the different variables affect the probability of being approved. In conclusion, we can deduct that race is not the first criteria influence the decision. Rather the two debt ratios are the main factors that determine people's approval chances. Other factors such discrimination in other areas of the society could be the reason that white applicants might have better access to education which leads to better job and income consequently better debt ratios. 

                                                          
